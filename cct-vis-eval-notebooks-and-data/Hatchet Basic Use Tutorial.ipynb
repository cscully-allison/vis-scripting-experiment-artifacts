{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef248a9d",
   "metadata": {},
   "source": [
    "# Hatchet Use Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86500592",
   "metadata": {},
   "source": [
    "Hello welcome to the hatchet tutorial and refrence sheet. Here you can find a quick overview of how to use hatchet and some helpful functions which will aid your use of hatchet. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e238f7",
   "metadata": {},
   "source": [
    "## Quick Reference Links\n",
    "\n",
    "1. [Convenience Functions](#section0)\n",
    "2. [Loading Data](#section1)\n",
    "3. [Seeing Data](#section2)\n",
    "    1. [Interactive Calling Context Tree Quickref](#section2-1)\n",
    "4. [Data Analysis](#section3)\n",
    "5. [Filtering and Retreving Queries](#section4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd28ef0",
   "metadata": {},
   "source": [
    "<a id='section0'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35807bca",
   "metadata": {},
   "source": [
    "# Part 0 - Convenience Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b824b89c",
   "metadata": {},
   "source": [
    "Before we begin we are going to import the hatchet library and define some functions which will help us later. These are not necessary for hatchet . . ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08578506",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hatchet as ht\n",
    "\n",
    "\"\"\"\n",
    "    The following are convenience functions provided to you for this tutorial, and define some common operations.\n",
    "    They cannot operate on dataframes produced from eachother,\n",
    "    so only use them on dataframes directly loaded from a dastaset\n",
    "\"\"\"\n",
    "\n",
    "def affixColumntoGraphframe(dest_gf, src_gf, colname_dest, colname_src):\n",
    "    \"\"\"\n",
    "        Attaches a column from one graph frame to another. Used by the subsequent functions.\n",
    "        Params:\n",
    "            dest_gf: the destination graphframe for the column\n",
    "            src_gf: the source graphframe for the column\n",
    "            colname_dest: the target column name on the desination graphframe\n",
    "            colname_src: the name of the column we would like to transfer from source\n",
    "    \"\"\"\n",
    "    gf_new = dest_gf.copy()\n",
    "    src_gf = src_gf.copy()\n",
    "    \n",
    "    src_gf.dataframe[colname_dest] = src_gf.dataframe[colname_src]\n",
    "    src_gf.dataframe = src_gf.dataframe.drop(columns=['time (inc)', 'time'])\n",
    "    \n",
    "    gf_new.dataframe = gf_new.dataframe \\\n",
    "                        .reset_index() \\\n",
    "                        .join( \\\n",
    "                            src_gf.dataframe.loc[src_gf.dataframe[\"_missing_node\"] == 0].reset_index().set_index(['nid','name']),\n",
    "                            on=['nid','name'], \n",
    "                            lsuffix='_l', \n",
    "                            rsuffix='_r'\n",
    "                        )\n",
    "\n",
    "    if('_missing_node' in gf_new.dataframe.columns):\n",
    "        gf_new.dataframe = gf_new.dataframe.drop(columns=['_missing_node'])\n",
    "    \n",
    "    removes = [c for c in gf_new.dataframe.columns if '_r' in c]\n",
    "    renames = {}\n",
    "    \n",
    "    for c in gf_new.dataframe.columns:\n",
    "        if c[-2:] == '_l':\n",
    "            renames[c] = c[:-2]\n",
    "    \n",
    "    gf_new.dataframe = gf_new.dataframe.drop(columns=removes).rename(columns=renames).set_index(['node'])\n",
    "\n",
    "    gf_new.exc_metrics.append(colname_dest)\n",
    "    \n",
    "    return gf_new\n",
    "\n",
    "def calcSpeedup(gf1, gf2):\n",
    "    # Calculates the speedup between two graph frames\n",
    "    # with the same function calls\n",
    "    # Returns: Copy of GF1 with a new column, speedup\n",
    "    gf1 = gf1.copy()\n",
    "    gf2 = gf2.copy()\n",
    "    gf1.drop_index_levels()\n",
    "    gf2.drop_index_levels()\n",
    "\n",
    "    speedup = gf1/gf2\n",
    "    \n",
    "    gf_new = affixColumntoGraphframe(gf1, speedup, \"speedup\", \"time\")\n",
    "    \n",
    "    return gf_new\n",
    "\n",
    "def calcDiff(gf1, gf2):\n",
    "    # Calculates the difference in runtimes between two graph frames\n",
    "    # with the same function calls\n",
    "    # Returns: Copy of GF1 with a new column, runtimediff\n",
    "    gf1 = gf1.copy()\n",
    "    gf2 = gf2.copy()\n",
    "    gf1.drop_index_levels()\n",
    "    gf2.drop_index_levels()\n",
    "\n",
    "    runtimediff = gf1-gf2\n",
    "\n",
    "    gf_new = affixColumntoGraphframe(gf1, runtimediff, \"runtimediff\", \"time\")\n",
    "    return gf_new\n",
    "    \n",
    "\n",
    "def calcImbalance(gf):\n",
    "    # Calculates the load imbalance across nodes in a single graph frame.\n",
    "    import numpy as np\n",
    "    gf1 = gf.copy()\n",
    "    gf2 = gf.copy()\n",
    "    gf1.drop_index_levels(function=np.mean)\n",
    "    gf2.drop_index_levels(function=np.max)\n",
    "    \n",
    "    gf1.dataframe['imbalance'] = gf2.dataframe['time'] / gf1.dataframe['time']\n",
    "    gf1.exc_metrics.append(\"imbalance\")\n",
    "    \n",
    "    return gf1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e354be70",
   "metadata": {},
   "source": [
    "<a id='section1'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1028654",
   "metadata": {},
   "source": [
    "# Part 1 - Loading Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86afe182",
   "metadata": {},
   "source": [
    "In this tutorial we will show you how to load two different types of files:\n",
    "1. HPCToolkit Files\n",
    "2. Caliper Files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ad03e9",
   "metadata": {},
   "source": [
    "## HPCToolkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8dc41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gf_hpc = ht.GraphFrame.from_hpctoolkit('datasets/osu_allgather.1.6.2019-08-26_18-37-57/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db50e396",
   "metadata": {},
   "source": [
    "## Caliper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d3999c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gf_cali = ht.GraphFrame.from_caliper(\"datasets/lulesh-scaling/lulesh-annotation-profile-1core.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a6eb0b",
   "metadata": {},
   "source": [
    "When a data file is passed into a hatchet `from_*` method it creates a GraphFrame. This GraphFrame is a combination Graph and Dataframe. The graph contains the function call hierarchy of in the loaded dataset. The dataframe is indexed by the nodes in our graph and contains all the metrics measured with each function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24745b16",
   "metadata": {},
   "source": [
    "<a id='section2'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07fb3e5f",
   "metadata": {},
   "source": [
    "# Part 2 - Seeing the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "790b7f56",
   "metadata": {},
   "source": [
    "Once a graphframe has been loaded, we can take a couple of approaches to view our data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb45c4fd",
   "metadata": {},
   "source": [
    "## Dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995280f6",
   "metadata": {},
   "source": [
    "First, we can look at the data directly through our dataframe. This dataframe can be used like a sortable flat profile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2b742f",
   "metadata": {},
   "outputs": [],
   "source": [
    "gf_cali.dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51e0746",
   "metadata": {},
   "source": [
    "We can sort this by inclusive time to get a rough idea of our call stack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a8ef37",
   "metadata": {},
   "outputs": [],
   "source": [
    "gf_cali.dataframe.sort_values([\"time (inc)\"], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4fded42",
   "metadata": {},
   "source": [
    "This can be useful for a quick glance at our data, however, we also have the graph on our graphframe and can visualize that, as well, to get a better idea of the structure of our program hierarchy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95529d93",
   "metadata": {},
   "source": [
    "## Console-Based Indented Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a2e268",
   "metadata": {},
   "source": [
    "The following command will print an indented tree showing our data hierarchy and one metric associated with each node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30820d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gf_cali.tree())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f6a8a7",
   "metadata": {},
   "source": [
    "This tree can give us a quick picture of our data. It works especially well with small datasets like the one we use here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baee5bf4",
   "metadata": {},
   "source": [
    "Unfortunately, with larger datasets it can be a little difficult to quickly get an idea of the shape of our tree and which nodes might be most important."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c4ed5f",
   "metadata": {},
   "source": [
    "We can see this with the hpc_toolkit data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6521308",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(gf_hpc.tree())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ba0396",
   "metadata": {},
   "source": [
    "To accomodate for these larger and more complicated datasets we provide an alternative interactive tree visualization designed for use in Jupyter notebooks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa990ea6",
   "metadata": {},
   "source": [
    "<a id=\"section2-1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daaa7515",
   "metadata": {},
   "source": [
    "## Interactive Calling Context Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbfb413b",
   "metadata": {},
   "source": [
    "The interactive calling context tree uses an special command called jupyter magics and requires us to load an extension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961d2163",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext hatchet.vis.loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aefe981",
   "metadata": {},
   "source": [
    "With this we can now call our visualization on either graph frame with the following magic function. (A magic function is any command that is prefaced by a `%` in jupyter. The calling context tree visualization provides two:\n",
    "1. `%cct <graphframe>` - This loads the calling context tree visualization\n",
    "2. `%cct_fetch_query <string>` - This retrieves a query which describes the current visualization configuration and stores it in the passed argument."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6100f1b",
   "metadata": {},
   "source": [
    "When you run the following command it will load the calling context tree visualization. To expand the cell and view the visualization without scrolling within the cell click the box to the immediate left of the visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16658bfb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%cct gf_hpc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cebae72a",
   "metadata": {},
   "source": [
    "The above tree is still fairly long, however it provides several advantages over a static console based representation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c677fa0c",
   "metadata": {},
   "source": [
    "### Interactive Visualization Features - Layout\n",
    "\n",
    "The cell above should look very simiar to the image here:\n",
    "\n",
    "![](layout_annotated.png)\n",
    "\n",
    "Here you can find descriptions of these key layout elements:\n",
    "\n",
    "1. This is the `main menu`. It behaves like a dropdown menu in a standard windows-like program. Each of the buttons on this menu will produce a dropdown with additional options. \n",
    "    1. `Metrics` contains options related to which metrics are associated with the color of nodes and which are associated with the size. In addition to color, you will see that one metric is labeled \"primary,\" this is the metric to which our `Mass Prune` functionality will be applied.\n",
    "    2. `Display` contains options related to how we are rendering the colors on the tree as well as which trees we are showing. \n",
    "    3. `Query` contains functions related to the reducing the size of our tree and retireving queries which describe the current configuration of the tree for later use.\n",
    "    \n",
    "2. Here you will see the `legends`. There are two legends because we encode two metrics on each node to allow for binary analysis. \n",
    "\n",
    "3. This is the `tree view`. Here you can scroll, zoom and select nodes on the tree."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b653122f",
   "metadata": {},
   "source": [
    "### Interactive Visualization Features - Basic Interaction\n",
    "\n",
    "At a high level, this Calling Context Tree Vis provides most standard functionality expected from an interactive visalization:\n",
    "\n",
    "1. `Click and Drag` on the tree to pan\n",
    "2. `Scroll` near the tree to zoom in and out\n",
    "    1. If you wish to scroll down the page its reccomended you move your mouse to the margins of the jupter notebook.\n",
    "3. Click the `Display > Reset View` menu option if wish to undo any pan and zoom.\n",
    "4. Select individual nodes in the tree by `clicking` on them\n",
    "    1. `Shift + Click` will allow you to select multiple nodes at once.\n",
    "    2. `Shift + Click` on an already selected node will deselect that node\n",
    "    \n",
    "Give each of these commands a try on the prior visualization before continuing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42cf9803",
   "metadata": {},
   "source": [
    "### Interactive Visualization Features - Advanced Interaction\n",
    "\n",
    "In the cases of large trees like we have above, it can be frustrating to frequently scroll past many nodes which we may not care about to get to the interesting nodes. Accordingly we provide functionality to prune back this tree to a more manageable size. Here is a list of those more advanced interactions.\n",
    "\n",
    "1. `Double Click` a node to collapse it and its children into an `aggregrate node`. This hides it from view and shows the average two metrics of all hidden nodes with its color and size.\n",
    "    1. `Double Click` a collapsed node to re-expand it.\n",
    "2. `Control + Double Click` a normal node to subsume it into its parent. This can be useful if there are nodes in a call path which add clutter to the tree but are not important to the understanding of how a program functions. For example, wrapper and helper functions that call functions doing real processing.\n",
    "3. Selecting `Query > Mass Prune` from the dropdown menu will cause a popup will appear. This popup is a tool you can use to rapidly cut away uninteresting nodes in your program:\n",
    "\n",
    "![](popup_layout.png)\n",
    "\n",
    "Layout descriptions:\n",
    "1. The top bar of the popup can be grabbed to drag and drop this window anywhere in the visualization.\n",
    "2. The violet top bars in this histogram show the frequency of nodes which can be pruned away within a certain metric range. The metric range they are grouped by is the `primary` \"color\" metric.\n",
    "3. The bottom bars show the number of nodes in this metric range which are zero-value internal nodes which are the ancestors of these nodes. They will not be pruned away until a full subtree of nodes is removed.\n",
    "4. These sliders are your primary interaction mechanism in this tool. `Click + Drag` either slider to prune away nodes outisde of the threshold specified under each slider."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c748bf",
   "metadata": {},
   "source": [
    "Here is the HPCToolkit data once again so you can try out this advanced functionality without having to scroll all the way back up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c4ab3a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%cct gf_hpc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05041b2e",
   "metadata": {},
   "source": [
    "<a id='section3'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a72270",
   "metadata": {},
   "source": [
    "# Part 3 - Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3acf7a67",
   "metadata": {},
   "source": [
    "Now that we have out tools for viewing and loading data, we will demonstrate some mechanisms for interacting with and modifying our graphframe."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df226e5d",
   "metadata": {},
   "source": [
    "### Mathemetical Operators"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a70a586",
   "metadata": {},
   "source": [
    "If we have two graph frames of similar shapes we can perform operations across our whole graphframe which applies to each node. A graphframe supports `+`,`-`,`*`,`/` between two graph frames.\n",
    "\n",
    "In the following example we will use the divide operator to calculate speedup between two graphframes. To do this, first we must load a second lulesh graphframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085171b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "gf_lulesh_64 = ht.GraphFrame.from_caliper(\"datasets/lulesh-scaling/lulesh-annotation-profile-64cores.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae8f978",
   "metadata": {},
   "outputs": [],
   "source": [
    "gf_lulesh_512 = ht.GraphFrame.from_caliper(\"datasets/lulesh-scaling/lulesh-annotation-profile-512cores.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16ede41",
   "metadata": {},
   "outputs": [],
   "source": [
    "gf_lulesh_speedup = gf_lulesh_64 / gf_lulesh_512"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f083049",
   "metadata": {},
   "source": [
    "The result of this division, speedup, is stored on each node in gf_lulesh_speedup as \"time\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb922579",
   "metadata": {},
   "outputs": [],
   "source": [
    "gf_lulesh_speedup.dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef1f063",
   "metadata": {},
   "source": [
    "We could visualize the results of this calculation like any other tree. However if we wish to see time and speedup at the same time on a single node, to identify clear optimization targets, this can be difficult with the console based tree. We need to print out both trees and compare them side by side."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e38f70",
   "metadata": {},
   "source": [
    "If we combine our speedup graphframe with our original graphframe through the use of the following helper function, we can visualize speedup and time on the each node at the same time. We can also view other data like load imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e53fea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gf_lulesh_speedup = calcSpeedup(gf_lulesh_64, gf_lulesh_512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf03ef66",
   "metadata": {},
   "outputs": [],
   "source": [
    "gf_lulesh_speedup = calcImbalance(gf_lulesh_speedup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30dcecd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%cct gf_lulesh_speedup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d597403",
   "metadata": {},
   "source": [
    "On this graph you will see that the `speedup` of a node is indicated with the blue-red color gradient, while `time` is shown with the node's relative size; bigger nodes mean more time. If you select `display > color map > inverted` from the dropdown menu, lower numbers will be highlighted red, indicating poor speedup.\n",
    "\n",
    "With this configuration we can see that the bottom left leaf and lower right trees look the most problematic, with relatively low speedup as we scale from 64 to 256 cores. To simplify our tree and focus only on this subtree we can manually collapse the top two subtrees at level 3 by double clicking the internal nodes we want them to `collapse into`. The result should be a tree that looks like the following:\n",
    "\n",
    "![](manual_prune.png)\n",
    "\n",
    "We can also remove some of these mpi nodes which seem to be cluttering up our tree by `ctrl + double click` on each you wish to remove."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56f818a",
   "metadata": {},
   "source": [
    "<a id='section4'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a23a0d6",
   "metadata": {},
   "source": [
    "# Part 4 - Filtering and Retireving Queries from the Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c8ce69",
   "metadata": {},
   "source": [
    "Above, we showed an example of modifying our tree via the interactive visualization: removing nodes which we are not useful to our analysis and clutter a tree. Unfortunately, these changes will be lost if the visualization is reloaded; so Hatchet provides functionality which allows us to reduce our source graphframe. The `filter` function.\n",
    "\n",
    "## Filter\n",
    "\n",
    "The `filter` class method can be called on a graphframe like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71124a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "gf_lulesh_low_speedup = gf_lulesh_speedup.filter(lambda x: x.speedup < 1);\n",
    "gf_lulesh_high_speedup = gf_lulesh_speedup.filter(\"MATCH (a) WHERE a.'speedup' >= 1\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da7c1b5",
   "metadata": {},
   "source": [
    "This filter function accepts two types of queries:\n",
    "1. lambda expressions that can operate on any metric on your dataframe, like the above example\n",
    "2. string based queries using a hatchet-specific query language. \n",
    "\n",
    "We will not go into detail explaining the syntax of the query language here; however it is much more powerful than the lambda expressions and allows the creation of more complex queries which are hard to specify mathematically. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c8da41",
   "metadata": {},
   "source": [
    "## Retriving a text based query from the visualization\n",
    "\n",
    "In the last part of this tutorial we modified a tree using manual interactions but no strict pattern of inclusivity: we removed MPI nodes and collapsed subtrees we weren't intrested in. If we want to apply these changes by filtering our graphframe we would need to articulate these series of decisions in a complex lambda function or string-based query. \n",
    "\n",
    "To avoid this manual transfer, the interactive visualization provides a means to export a snapshot of the tree in query-language form back to the jupyter notebook, which can be applied to the original graphframe and stored for later use.\n",
    "\n",
    "**To export the query, return to the visualization and select `Query > Get Snapshot Query` from top menu.**\n",
    "\n",
    "After that you can run the following command to store the query in the argument to our magic function: `nodeSubselection`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f713776",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cct_fetch_query nodeSubselection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8203671",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodeSubselection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82cef6d7",
   "metadata": {},
   "source": [
    "By applying this query to our original graphframe, it modfies our data on the python side so we can now call our visualizations or examine our dataframes on a more narrow potion of our calling context tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48102e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_index_levels()\n",
    "gf_snapshot = gf_lulesh_speedup.filter(nodeSubselection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b8cfb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cct gf_snapshot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3860f5eb",
   "metadata": {},
   "source": [
    "We can also store this query for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a067d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('lulesh_optimization_target_query.txt', 'w') as f:\n",
    "    f.write(nodeSubselection)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9eeba2",
   "metadata": {},
   "source": [
    "And, when we want to re-use it, we can read it into a variable and reduce our graphframe pre-visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b14b6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = ''\n",
    "with open('lulesh_optimization_target_query.txt', 'r') as f:\n",
    "    query = f.read()\n",
    "\n",
    "# If we closed this notebook an re-oepned it, \n",
    "# we would need to re-caluclate speedup, because \n",
    "# it is a derived metric which was not stored on the source graphframes\n",
    "gf_lulesh_64 = ht.GraphFrame.from_caliper(\"datasets/lulesh-scaling/lulesh-annotation-profile-64cores.json\")\n",
    "gf_lulesh_512 = ht.GraphFrame.from_caliper(\"datasets/lulesh-scaling/lulesh-annotation-profile-512cores.json\")\n",
    "gf_lulesh_speedup = calcSpeedup(gf_lulesh_64, gf_lulesh_512)\n",
    "\n",
    "print(query)\n",
    "\n",
    "recovered_gf_lulesh_snapshot = gf_lulesh_speedup.filter(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3441d6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cct recovered_gf_lulesh_snapshot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7c092d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
